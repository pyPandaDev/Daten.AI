<<<<<<< HEAD
# ðŸ¤– Daten.AI - AI-Powered Data Analysis Platform

<div align="center">

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![React](https://img.shields.io/badge/React-18-blue.svg)
![TypeScript](https://img.shields.io/badge/TypeScript-5.2-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-Latest-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

An **AI-powered data analysis platform** that transforms raw data into actionable insights using **Google Gemini AI**. Upload your dataset, let AI suggest analysis tasks, and watch as beautiful visualizations and reports are generated in real-time.

[Quick Start](#-quick-start) â€¢ [Features](#-features) â€¢ [Documentation](#-documentation) â€¢ [API](#-api-endpoints)

</div>

---

## âœ¨ Features

### ðŸŽ¯ Core Capabilities
- **ðŸ¤– AI-Powered Analysis** - Google Gemini AI understands your data and suggests 8+ relevant analysis tasks
- **âš¡ Real-Time Streaming** - Watch analysis progress with Server-Sent Events (SSE)
- **ðŸ“Š Comprehensive Analysis** - EDA, data cleaning, visualization, feature engineering, and ML modeling
- **ðŸ“„ Beautiful Reports** - Export to PDF or CSV with professional formatting
- **ðŸ”„ Continuous Workflow** - Execute follow-up analyses based on previous results
- **ðŸ’¬ Interactive Chat** - Ask questions about your data and results with AI assistance

### ðŸ›¡ï¸ Production-Ready
- **Thread-Safe Architecture** - Supports unlimited concurrent users
- **Error Boundaries** - Graceful error handling prevents app crashes
- **Smart Polling Fallback** - SSE with intelligent polling backup (80% fewer API calls)
- **File Validation** - 50MB limit with type checking (CSV, Excel, JSON)
- **Auto-Retry Logic** - Network failures automatically retry 3x
- **Memory Management** - Automatic cleanup after 1 hour, zero memory leaks

### ðŸŽ¨ Modern Tech Stack
- **Frontend**: React 18 + TypeScript + Tailwind CSS + Zustand
- **Backend**: FastAPI + Python 3.9+ + Google Gemini AI
- **Data Science**: Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn
- **Real-Time**: Server-Sent Events (SSE) for streaming updates

## ðŸ—ï¸ Architecture

### Frontend (React + Vite)
- **React 18** with TypeScript for type safety
- **Tailwind CSS** for modern, responsive styling
- **Lucide React** for beautiful icons
- **Axios** for API communication
- **React Dropzone** for drag-and-drop file uploads
- **Server-Sent Events** for real-time updates

### Backend (FastAPI)
- **FastAPI** for high-performance async API
- **Google Gemini AI** for intelligent task planning and code generation
- **Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn** for data analysis
- **ReportLab** for PDF generation
- **Server-Sent Events** for streaming execution progress

## ðŸ“‹ Prerequisites

Before you begin, ensure you have:

| Requirement | Version | Download |
|-------------|---------|----------|
| **Python** | 3.9 or higher | [python.org](https://www.python.org/downloads/) |
| **Node.js** | 18 or higher | [nodejs.org](https://nodejs.org/) |
| **Google Gemini API Key** | - | [Get API Key](https://makersuite.google.com/app/apikey) |

> **Note**: The API key is **required** for AI-powered analysis. Free tier available with generous limits.

## ðŸš€ Quick Start

### One-Command Startup (Windows)

```bash
# Navigate to project directory
cd "C:\project\data science"

# Run the automated startup script
start.bat
```

The script will:
1. âœ… Check Python and Node.js installation
2. âœ… Create virtual environment (if needed)
3. âœ… Install all dependencies
4. âœ… Start backend server (http://localhost:8000)
5. âœ… Start frontend dev server (http://localhost:5173)
6. âœ… Open browser automatically

---

### Manual Setup (All Platforms)

#### 1ï¸âƒ£ Backend Setup

```bash
# Navigate to backend
cd backend

# Create virtual environment
python -m venv venv

# Activate it
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### 2ï¸âƒ£ Configure Environment

```bash
# Copy environment template
cp .env.example .env  # Mac/Linux
copy .env.example .env  # Windows
```

**Edit `.env` and add your credentials:**

```env
# REQUIRED: Get from https://makersuite.google.com/app/apikey
GEMINI_API_KEY=AIzaSy..._your_actual_key_here

# OPTIONAL: Advanced Configuration
GEMINI_MODEL=gemini-1.5-flash
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
CORS_ORIGINS=http://localhost:5173
MAX_FILE_SIZE_MB=50
EXECUTION_TIMEOUT_SECONDS=300
```

> âš ï¸ **Security**: Never commit `.env` to version control!

#### 3ï¸âƒ£ Frontend Setup

```bash
# Navigate to frontend
cd frontend

# Install dependencies
npm install

# (Optional) Create frontend env for custom API URL
echo "VITE_API_URL=http://localhost:8000/api" > .env.local
```

#### 4ï¸âƒ£ Run the Application

**Terminal 1 - Backend:**
```bash
cd backend
venv\Scripts\activate  # Windows
python -m uvicorn app.main:app --reload
```
âœ… Backend: http://localhost:8000

**Terminal 2 - Frontend:**
```bash
cd frontend
npm run dev
```
âœ… Frontend: http://localhost:5173

**Terminal 3 - Health Check (Optional):**
```bash
curl http://localhost:8000/health
```

---

### ðŸŽ‰ You're Ready!

Open your browser to **http://localhost:5173** and start analyzing!

---

## ðŸ“– Usage Guide

### 1ï¸âƒ£ Upload Your Dataset

**Supported Formats:**
- ðŸ“„ CSV (`.csv`)
- ðŸ“Š Excel (`.xlsx`, `.xls`)
- ðŸ“‹ JSON (`.json`)
- ðŸ“¦ Parquet (`.parquet`)

**Limits:**
- Maximum file size: **50 MB**
- Validation: Automatic file type and size checking
- Storage: In-memory with 1-hour auto-cleanup

**How:**
1. Drag & drop your file OR click to browse
2. (Optional) Describe your goal: "Predict sales", "Find outliers", etc.
3. Click "Upload" and watch AI analyze your data

### 2ï¸âƒ£ Get AI-Powered Suggestions

**What Happens:**
- ðŸ¤– AI analyzes your dataset schema, types, and patterns
- ðŸ“‹ Suggests 8+ relevant tasks across categories:
  - **EDA**: Statistical summary, outlier detection, distributions
  - **Cleaning**: Missing values, duplicates, data types
  - **Visualization**: Plots, heatmaps, correlations
  - **Feature Engineering**: Date features, interactions, aggregations
  - **Modeling**: Regression, classification, clustering
  - **Statistical Testing**: Hypothesis tests, significance

**Task Information:**
- âœ… Task title and description
- â±ï¸ Estimated execution time
- ðŸŽ¯ Priority level (High/Medium/Low)
- ðŸ“Š Category badge

### 3ï¸âƒ£ Execute Analysis

**Execution Flow:**
1. **Select Task** - Click any suggested task
2. **Review Details** - See description, time estimate, priority
3. **Run Analysis** - Click "Run Analysis" button
4. **Watch Live** - Real-time streaming shows:
   - ðŸ“ Planning phase
   - ðŸ’» Code generation
   - âš¡ Execution progress
   - ðŸ“Š Results streaming

**Behind the Scenes:**
- AI generates Python code tailored to YOUR data
- Code executes in isolated environment
- Results parse in real-time (SSE)
- Smart fallback if SSE fails
- Auto-retry on errors (up to 2 attempts)

### 4ï¸âƒ£ Review Results

**Results Dashboard Includes:**

| Section | What You Get |
|---------|-------------|
| ðŸ“‹ **Executive Summary** | AI-generated insights and key findings |
| ðŸ“ **Analysis Plan** | Step-by-step breakdown of execution |
| ðŸ“Š **Visualizations** | Interactive charts, plots, heatmaps |
| ðŸ“‘ **Tables** | Summary statistics, data samples |
| ðŸ“ˆ **Metrics** | KPIs, performance indicators |
| ðŸ’» **Python Code** | Full generated code (expandable) |
| ðŸ”„ **Follow-ups** | AI suggests next analysis steps |
| ðŸ’¬ **Results Chat** | Ask questions about the results |

**Interactive Features:**
- Expand/collapse code sections
- Download visualizations as PNG
- Copy code to clipboard
- Ask AI questions about results
- Execute follow-up analyses

### 5ï¸âƒ£ Export & Share

**Export Options:**

| Format | What's Included | Use Case |
|--------|-----------------|----------|
| ðŸ“„ **PDF Report** | Summary, plots, code, metrics | Share with stakeholders |
| ðŸ“Š **CSV Data** | Processed/cleaned dataset | Further analysis |
| ðŸ’» **Code** | Python code (copy-paste) | Reproduce analysis |

**How to Export:**
1. Click **Export** button in results header
2. Choose format (PDF or CSV)
3. File downloads automatically
4. Named with timestamp for easy tracking

---

## ðŸŽ¯ Example Use Cases

### Exploratory Data Analysis
```
Upload: sales_data.csv
Goal: "Understand sales patterns and trends"
Results: Distribution plots, correlation heatmaps, time series analysis
```

### Missing Data Analysis
```
Upload: customer_data.xlsx
Task: "Analyze Missing Data"
Results: Missing value heatmap, percentage by column, suggestions for imputation
```

### Predictive Modeling
```
Upload: housing_prices.csv
Goal: "Predict house prices"
Results: Feature importance, model performance metrics, prediction accuracy
```

### Outlier Detection
```
Upload: sensor_readings.json
Task: "Identify Outliers"
Results: Box plots, Z-score analysis, flagged anomalies
```

## ðŸ”Œ API Endpoints

### Upload Dataset
```http
POST /api/upload
Content-Type: multipart/form-data
```

### Get Task Suggestions
```http
POST /api/suggest
Content-Type: application/json

{
  "file_id": "uuid",
  "dataset_schema": {...},
  "user_goal": "optional goal description"
}
```

### Run Analysis Task
```http
POST /api/run
Content-Type: application/json

{
  "file_id": "uuid",
  "task_id": "task_id",
  "task_title": "Task Title",
  "dataset_schema": {...},
  "parameters": {}
}
```

### Stream Execution Events
```http
GET /api/stream/{task_execution_id}
Accept: text/event-stream
```

### Export to PDF
```http
POST /api/export/pdf
Content-Type: application/json

{
  "task_execution_id": "uuid",
  "export_type": "pdf"
}
```

### Export to CSV
```http
POST /api/export/csv
Content-Type: application/json

{
  "task_execution_id": "uuid",
  "export_type": "csv"
}
```

## ðŸ“ Project Structure

```
project/
â”œâ”€â”€ frontend/                     # React + Vite frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/           # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ FileUploader.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ TaskSuggestions.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatPanel.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ResultViewer.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ExportPanel.tsx
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts            # API client
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â””â”€â”€ useStream.ts      # SSE hook
â”‚   â”‚   â”œâ”€â”€ App.tsx               # Main app component
â”‚   â”‚   â”œâ”€â”€ main.tsx              # Entry point
â”‚   â”‚   â””â”€â”€ index.css             # Global styles
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ tailwind.config.js
â”‚
â”œâ”€â”€ backend/                      # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py               # FastAPI app
â”‚   â”‚   â”œâ”€â”€ routers/              # API routes
â”‚   â”‚   â”‚   â”œâ”€â”€ upload.py
â”‚   â”‚   â”‚   â”œâ”€â”€ suggest.py
â”‚   â”‚   â”‚   â”œâ”€â”€ run.py
â”‚   â”‚   â”‚   â”œâ”€â”€ stream.py
â”‚   â”‚   â”‚   â””â”€â”€ export.py
â”‚   â”‚   â”œâ”€â”€ services/             # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ gemini_client.py  # Gemini AI integration
â”‚   â”‚   â”‚   â”œâ”€â”€ code_executor.py  # Safe code execution
â”‚   â”‚   â”‚   â”œâ”€â”€ planner.py        # Dataset analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ pdf_service.py    # PDF generation
â”‚   â”‚   â”‚   â””â”€â”€ storage.py        # In-memory storage
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py        # Pydantic models
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ streaming.py      # SSE utilities
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ .env.example                  # Environment template
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ðŸ”§ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `GEMINI_API_KEY` | Google Gemini API key | Required |
| `GEMINI_MODEL` | Gemini model to use | `gemini-1.5-flash` |
| `BACKEND_HOST` | Backend server host | `0.0.0.0` |
| `BACKEND_PORT` | Backend server port | `8000` |
| `CORS_ORIGINS` | Allowed CORS origins | `http://localhost:5173` |
| `MAX_FILE_SIZE_MB` | Max upload file size | `50` |
| `EXECUTION_TIMEOUT_SECONDS` | Code execution timeout | `300` |

### Frontend Configuration

Create `frontend/.env.local` for custom API URL:

```env
VITE_API_URL=http://localhost:8000/api
```

## ðŸ›¡ï¸ Security Considerations

- Dataset files are stored in memory and automatically cleaned after 1 hour
- Code execution is sandboxed and doesn't allow file system writes or network calls
- All user inputs are validated and sanitized
- API rate limiting should be configured for production use
- CORS is properly configured to allow only specified origins

## ðŸš€ Deployment

### Backend Deployment

The backend can be deployed to platforms like:
- **Heroku**: Use the included `Procfile`
- **Railway**: Direct Python app deployment
- **Google Cloud Run**: Containerize with Docker
- **AWS Lambda**: Use Mangum adapter for FastAPI

### Frontend Deployment

The frontend can be deployed to:
- **Vercel**: Automatic deployment from Git
- **Netlify**: Connect your repository
- **GitHub Pages**: Build and deploy static files
- **Cloudflare Pages**: Fast global CDN

## ðŸ› Troubleshooting

### Backend Issues

**ModuleNotFoundError**
```bash
# Ensure virtual environment is activated
pip install -r requirements.txt
```

**Gemini API Error**
```bash
# Check API key is correct in .env file
# Verify API key has proper permissions
```

### Frontend Issues

**Module not found**
```bash
# Delete node_modules and reinstall
rm -rf node_modules
npm install
```

**CORS Error**
```bash
# Check CORS_ORIGINS in .env includes your frontend URL
```

## ðŸ“ Development

### Running Tests

```bash
# Backend tests
cd backend
pytest

# Frontend tests
cd frontend
npm test
```

### Code Formatting

```bash
# Backend
black app/
isort app/

# Frontend
npm run lint
```

## ðŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ðŸ“„ License

MIT License - feel free to use this project for any purpose.

## ðŸ™ Acknowledgments

- **Google Gemini AI** for powering intelligent analysis
- **FastAPI** for the excellent web framework
- **React** and **Vite** for modern frontend development
- **Tailwind CSS** for beautiful styling
- All the amazing open-source data science libraries

## ðŸ“§ Support

For issues, questions, or suggestions:
- Open an issue on GitHub
- Check existing documentation
- Review example use cases

---

**Built with â¤ï¸ using AI-powered development tools**
=======
# Daten.AI
>>>>>>> fd3d894143c6adefdefa0d0c90de6f00de35b18f
